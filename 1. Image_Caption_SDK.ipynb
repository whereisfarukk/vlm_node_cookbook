{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align=\"center\">\n",
        "<p align=\"center\" style=\"width: 100%;\">\n",
        "    <img src=\"https://raw.githubusercontent.com/vlm-run/.github/refs/heads/main/profile/assets/vlm-black.svg\" alt=\"VLM Run Logo\" width=\"80\" style=\"margin-bottom: -5px; color: #2e3138; vertical-align: middle; padding-right: 5px;\"><br>\n",
        "</p>\n",
        "<p align=\"center\"><a href=\"https://docs.vlm.run\"><b>Website</b></a> | <a href=\"https://docs.vlm.run/\"><b>API Docs</b></a> | <a href=\"https://docs.vlm.run/blog\"><b>Blog</b></a> | <a href=\"https://discord.gg/AMApC2UzVY\"><b>Discord</b></a>\n",
        "</p>\n",
        "<p align=\"center\">\n",
        "<a href=\"https://discord.gg/AMApC2UzVY\"><img alt=\"Discord\" src=\"https://img.shields.io/badge/discord-chat-purple?color=%235765F2&label=discord&logo=discord\"></a>\n",
        "<a href=\"https://twitter.com/vlmrun\"><img alt=\"Twitter Follow\" src=\"https://img.shields.io/twitter/follow/vlmrun.svg?style=social&logo=twitter\"></a>\n",
        "</p>\n",
        "</div>\n",
        "\n",
        "Welcome to **[VLM Run Cookbooks](https://github.com/vlm-run/vlmrun-cookbook)**, a comprehensive collection of examples and notebooks demonstrating the power of structured visual understanding using the [VLM Run Platform](https://app.vlm.run).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image Captioning & Tagging with VLM Run SDK\n",
        "\n",
        "This notebook demonstrates how to use the **official VLM Run Node.js SDK** (`vlmrun` npm package) to generate detailed captions and tags for images. Image captioning is perfect for:\n",
        "- **Accessibility**: Creating alt-text descriptions for images\n",
        "- **Content Management**: Automatically organizing and cataloging image libraries\n",
        "- **SEO**: Generating image descriptions for better search engine optimization\n",
        "- **Automated Analysis**: Building workflows that understand visual content\n",
        "\n",
        "We'll use VLM Run's vision-language models through the native SDK to generate comprehensive, contextual captions and extract relevant tags from various images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Environment Setup\n",
        "\n",
        "To get started, install the VLM Run SDK and sign up for an API key on the [VLM Run App](https://app.vlm.run).\n",
        "- Store the VLM Run API key under the `VLMRUN_API_KEY` environment variable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "\n",
        "* Node.js 18+\n",
        "* VLM Run API key (get one at [app.vlm.run](https://app.vlm.run))\n",
        "* Deno or tslab kernel for running TypeScript in Jupyter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "First, let's install the required packages:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "// Install the VLM Run SDK\n",
        "// npm install vlmrun openai zod\n",
        "\n",
        "// If using Deno kernel, install dependencies via npm specifiers\n",
        "// For tslab, run: npm install vlmrun openai zod in your project directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "// Import the VLM Run SDK and dependencies\n",
        "import { VlmRun } from \"vlmrun\";\n",
        "import { z } from \"zod\";\n",
        "import { zodToJsonSchema } from \"zod-to-json-schema\";\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ API Key loaded successfully\n"
          ]
        }
      ],
      "source": [
        "// Get API key from environment variable\n",
        "const VLMRUN_API_KEY = Deno.env.get(\"VLMRUN_API_KEY\");\n",
        "\n",
        "if (!VLMRUN_API_KEY) {\n",
        "    throw new Error(\"Please set the VLMRUN_API_KEY environment variable\");\n",
        "}\n",
        "\n",
        "console.log(\"âœ“ API Key loaded successfully\");\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's initialize the VLM Run client using the SDK\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ VLM Run SDK client initialized!\n"
          ]
        }
      ],
      "source": [
        "// Initialize the VLM Run client using the SDK\n",
        "const client = new VlmRun({\n",
        "    apiKey: VLMRUN_API_KEY,\n",
        "    baseURL: \"https://agent.vlm.run/v1\"  // Use the agent API endpoint\n",
        "});\n",
        "\n",
        "console.log(\"âœ“ VLM Run SDK client initialized!\");\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 1: Simple Image Captioning with Agent Completions\n",
        "\n",
        "The VLM Run SDK provides an OpenAI-compatible `agent.completions` interface that makes it easy to use familiar patterns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“· Image URL: https://storage.googleapis.com/vlm-data-public-prod/hub/examples/image.object-detection/crossroad.jpg\n",
            "\n",
            "ğŸ” Generating caption using VLM Run SDK...\n",
            "\n",
            "Caption: This detailed street scene captures a bustling urban environment, characterized by numerous pedestrians and a moderate flow of vehicles amidst tall city buildings. In the foreground, a family of four is prominently crossing a white-striped crosswalk: a bearded man in a light blue shirt and khaki pants, wearing earbuds and holding a phone; a woman in a dark jacket pushing a stroller with a baby; and a young child walking beside them. To their left, another man with a backpack, dressed in a dark coat and blue jeans, is also crossing. Further back on the right, a man in dark attire stands near a yellow taxi. Many other pedestrians are visible on the sidewalks and further down the street, indicating high foot traffic.\n",
            "\n",
            "Vehicles include a prominent yellow Toyota RAV4 taxi stopped in the crosswalk, and a dark red Hyundai Santa Fe SUV to its immediate left. The street extending into the background is populated with various other cars, including several dark sedans/SUVs, a silver SUV, a white cargo van, and another yellow taxi further in the distance. The overall atmosphere is one of dynamic city life, with pedestrians and vehicles coexisting on a busy thoroughfare lined by towering commercial buildings adorned with numerous signs and billboards, all under what appears to be a clear sky. The scene conveys the typical vibrant activity of a major metropolitan area.\n"
          ]
        }
      ],
      "source": [
        "// Example image URL\n",
        "const imageUrl = \"https://storage.googleapis.com/vlm-data-public-prod/hub/examples/image.object-detection/crossroad.jpg\";\n",
        "\n",
        "console.log(\"ğŸ“· Image URL:\", imageUrl);\n",
        "console.log(\"\\nğŸ” Generating caption using VLM Run SDK...\\n\");\n",
        "\n",
        "// Use the agent.completions interface (OpenAI-compatible)\n",
        "const response = await client.agent.completions.create({\n",
        "    model: \"vlm-agent-1\",\n",
        "    messages: [\n",
        "        {\n",
        "            role: \"user\",\n",
        "            content: [\n",
        "                { type: \"text\", text: \"Generate a detailed caption for this image\" },\n",
        "                { type: \"image_url\", image_url: { url: imageUrl } }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "});\n",
        "\n",
        "const caption = response.choices[0].message.content;\n",
        "console.log(`Caption: ${caption}`);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Function for Captioning\n",
        "\n",
        "Let's create a reusable helper function using the VLM Run SDK:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Helper function defined\n"
          ]
        }
      ],
      "source": [
        "/**\n",
        " * Generate a caption for an image using VLM Run SDK.\n",
        " * \n",
        " * @param imageUrl - URL of the image to caption\n",
        " * @param prompt - Custom prompt for captioning (optional)\n",
        " * @returns Generated caption string\n",
        " */\n",
        "async function generateCaption(\n",
        "    imageUrl: string,\n",
        "    prompt: string = \"Generate a detailed caption for this image\"\n",
        "): Promise<string> {\n",
        "    const response = await client.agent.completions.create({\n",
        "        model: \"vlm-agent-1\",\n",
        "        messages: [\n",
        "            {\n",
        "                role: \"user\",\n",
        "                content: [\n",
        "                    { type: \"text\", text: prompt },\n",
        "                    { type: \"image_url\", image_url: { url: imageUrl } }\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    });\n",
        "    \n",
        "    return response.choices[0].message.content || \"\";\n",
        "}\n",
        "\n",
        "console.log(\"âœ“ Helper function defined\");\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 2: Structured Output with Zod Schema\n",
        "\n",
        "For production applications, you'll want structured JSON output. Let's use Zod schemas with the VLM Run SDK:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ ImageCaption schema defined\n",
            "Schema: {\n",
            "  \"type\": \"object\",\n",
            "  \"properties\": {\n",
            "    \"caption\": {\n",
            "      \"type\": \"string\",\n",
            "      \"description\": \"Detailed caption of the scene\"\n",
            "    },\n",
            "    \"tags\": {\n",
            "      \"type\": \"array\",\n",
            "      \"items\": {\n",
            "        \"type\": \"string\"\n",
            "      },\n",
            "      \"description\": \"Tags that describe the image\"\n",
            "    },\n",
            "    \"primary_objects\": {\n",
            "      \"type\": \"array\",\n",
            "      \"items\": {\n",
            "        \"type\": \"string\"\n",
            "      },\n",
            "      \"description\": \"Main objects visible in the image\"\n",
            "    },\n",
            "    \"scene_type\": {\n",
            "      \"type\": \"string\",\n",
            "      \"description\": \"Type of scene (e.g., indoor, outdoor, street, nature)\"\n",
            "    },\n",
            "    \"mood\": {\n",
            "      \"type\": \"string\",\n",
            "      \"description\": \"Overall mood or atmosphere of the image\"\n",
            "    }\n",
            "  },\n",
            "  \"required\": [\n",
            "    \"caption\",\n",
            "    \"tags\",\n",
            "    \"primary_objects\",\n",
            "    \"scene_type\",\n",
            "    \"mood\"\n",
            "  ],\n",
            "  \"additionalProperties\": false,\n",
            "  \"$schema\": \"http://json-schema.org/draft-07/schema#\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "// Define the schema using Zod\n",
        "const ImageCaptionSchema = z.object({\n",
        "    caption: z.string().describe(\"Detailed caption of the scene\"),\n",
        "    tags: z.array(z.string()).describe(\"Tags that describe the image\"),\n",
        "    primary_objects: z.array(z.string()).describe(\"Main objects visible in the image\"),\n",
        "    scene_type: z.string().describe(\"Type of scene (e.g., indoor, outdoor, street, nature)\"),\n",
        "    mood: z.string().describe(\"Overall mood or atmosphere of the image\")\n",
        "});\n",
        "\n",
        "// Type inference from schema\n",
        "type ImageCaption = z.infer<typeof ImageCaptionSchema>;\n",
        "\n",
        "console.log(\"âœ“ ImageCaption schema defined\");\n",
        "console.log(\"Schema:\", JSON.stringify(zodToJsonSchema(ImageCaptionSchema), null, 2));\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ” Generating structured caption...\n",
            "\n",
            "Raw JSON Response:\n",
            "{\"caption\":\"Pedestrians, including a family with a stroller, cross a busy city street in front of a yellow taxi cab, with numerous cars and towering buildings in the background, suggesting a bustling urban environment like New York City.\",\"mood\":\"bustling\",\"primary_objects\":[\"pedestrians\",\"yellow taxi\",\"cars\",\"buildings\",\"street\",\"crosswalk\",\"stroller\"],\"scene_type\":\"urban street scene\",\"tags\":[\"city street\",\"urban\",\"pedestrians\",\"traffic\",\"taxi\",\"crosswalk\",\"buildings\",\"daytime\",\"New York City\",\"cars\",\"stroller\",\"people\"]}\n",
            "\n",
            "âœ“ Validated Object:\n",
            "{\n",
            "  caption: \"Pedestrians, including a family with a stroller, cross a busy city street in front of a yellow taxi cab, with numerous cars and towering buildings in the background, suggesting a bustling urban environment like New York City.\",\n",
            "  tags: [\n",
            "    \"city street\",   \"urban\",\n",
            "    \"pedestrians\",   \"traffic\",\n",
            "    \"taxi\",          \"crosswalk\",\n",
            "    \"buildings\",     \"daytime\",\n",
            "    \"New York City\", \"cars\",\n",
            "    \"stroller\",      \"people\"\n",
            "  ],\n",
            "  primary_objects: [\n",
            "    \"pedestrians\",\n",
            "    \"yellow taxi\",\n",
            "    \"cars\",\n",
            "    \"buildings\",\n",
            "    \"street\",\n",
            "    \"crosswalk\",\n",
            "    \"stroller\"\n",
            "  ],\n",
            "  scene_type: \"urban street scene\",\n",
            "  mood: \"bustling\"\n",
            "}\n",
            "\n",
            "ğŸ“ Formatted Output:\n",
            "Caption: Pedestrians, including a family with a stroller, cross a busy city street in front of a yellow taxi cab, with numerous cars and towering buildings in the background, suggesting a bustling urban environment like New York City.\n",
            "Tags: city street, urban, pedestrians, traffic, taxi, crosswalk, buildings, daytime, New York City, cars, stroller, people\n",
            "Primary Objects: pedestrians, yellow taxi, cars, buildings, street, crosswalk, stroller\n",
            "Scene Type: urban street scene\n",
            "Mood: bustling\n"
          ]
        }
      ],
      "source": [
        "/**\n",
        " * Generate a structured caption using VLM Run SDK with Zod schema validation.\n",
        " * \n",
        " * @param imageUrl - URL of the image to analyze\n",
        " * @returns Validated ImageCaption object\n",
        " */\n",
        "async function generateStructuredCaption(imageUrl: string): Promise<ImageCaption> {\n",
        "    const response = await client.agent.completions.create({\n",
        "        model: \"vlm-agent-1\",\n",
        "        messages: [\n",
        "            {\n",
        "                role: \"user\",\n",
        "                content: [\n",
        "                    { \n",
        "                        type: \"text\", \n",
        "                        text: \"Analyze this image and provide a detailed caption, relevant tags, primary objects, scene type, and mood.\" \n",
        "                    },\n",
        "                    { \n",
        "                        type: \"image_url\", \n",
        "                        image_url: { url: imageUrl, detail: \"auto\" } \n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        // Use VLM Run's response_format with schema at top level\n",
        "        response_format: { \n",
        "            type: \"json_schema\", \n",
        "            schema: zodToJsonSchema(ImageCaptionSchema)\n",
        "        } as any\n",
        "    });\n",
        "    \n",
        "    const rawContent = response.choices[0].message.content || \"{}\";\n",
        "    console.log(\"Raw JSON Response:\");\n",
        "    console.log(rawContent);\n",
        "    console.log();\n",
        "    \n",
        "    // Parse and validate the response with Zod\n",
        "    const parsed = JSON.parse(rawContent);\n",
        "    return ImageCaptionSchema.parse(parsed);\n",
        "}\n",
        "\n",
        "// Generate structured caption\n",
        "console.log(\"ğŸ” Generating structured caption...\\n\");\n",
        "const structuredResult = await generateStructuredCaption(imageUrl);\n",
        "\n",
        "console.log(\"âœ“ Validated Object:\");\n",
        "console.log(structuredResult);\n",
        "console.log();\n",
        "console.log(\"ğŸ“ Formatted Output:\");\n",
        "console.log(`Caption: ${structuredResult.caption}`);\n",
        "console.log(`Tags: ${structuredResult.tags.join(\", \")}`);\n",
        "console.log(`Primary Objects: ${structuredResult.primary_objects.join(\", \")}`);\n",
        "console.log(`Scene Type: ${structuredResult.scene_type}`);\n",
        "console.log(`Mood: ${structuredResult.mood}`);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 3: Batch Processing Multiple Images\n",
        "\n",
        "Process multiple images efficiently using the VLM Run SDK:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing: Street Scene...\n",
            "Raw JSON Response:\n",
            "{\"caption\":\"A busy urban street scene captures diverse pedestrians utilizing a crosswalk, with a man in a light blue shirt and khaki pants walking alongside a woman and two young children, one in a stroller. Another man with a backpack crosses on the left. Several yellow taxi cabs are visible on the street amidst other vehicles, including a red SUV and a white van, all surrounded by towering city buildings featuring advertisements and architectural details. The overall impression is a bustling daytime atmosphere in a major metropolitan area.\",\"mood\":\"Bustling and dynamic, reflecting a typical active urban environment.\",\"primary_objects\":[\"people\",\"cars\",\"buildings\",\"street\"],\"scene_type\":\"City street\",\"tags\":[\"city street\",\"urban\",\"New York City\",\"pedestrians\",\"traffic\",\"cars\",\"taxi\",\"crosswalk\",\"buildings\",\"people\",\"family\",\"baby stroller\",\"daytime\",\"downtown\"]}\n",
            "\n",
            "Processing: Mountain...\n",
            "Raw JSON Response:\n",
            "{\"caption\":\"A breathtaking mountain landscape at sunrise, featuring majestic snow-capped peaks rising above a soft sea of clouds that fills the valley. The warm hues of the dawn sky, illuminated by the rising sun, cast a golden glow across the serene and awe-inspiring scene, highlighting the dramatic contrast between the rugged mountains and the gentle clouds.\",\"mood\":\"serene and awe-inspiring\",\"primary_objects\":[\"majestic peaks\",\"sea of clouds\",\"dawn sky\",\"rising sun\"],\"scene_type\":\"outdoor mountain landscape\",\"tags\":[\"mountain landscape\",\"sunrise\",\"snow-capped mountains\",\"clouds\",\"golden glow\",\"nature\",\"scenic\",\"dawn\"]}\n",
            "\n",
            "Processing: Cat...\n",
            "Raw JSON Response:\n",
            "{\"caption\":\"A black and white cat with striking green eyes looks directly at the camera, resting its paws on a bamboo-like surface against a plain green background.\",\"mood\":\"Calm, curious, attentive\",\"primary_objects\":[\"cat\",\"bamboo surface\"],\"scene_type\":\"Indoor\",\"tags\":[\"cat\",\"pet\",\"domestic cat\",\"black and white cat\",\"green eyes\",\"animal\",\"feline\",\"portrait\",\"indoor\",\"bamboo\",\"green wall\",\"cute\"]}\n",
            "\n",
            "\n",
            "=== Batch Processing Results ===\n",
            "\n",
            "â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "â”‚ (idx) â”‚ Image          â”‚ Caption                                                 â”‚ Tags                                                                                                                                          â”‚ Scene                        â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚     0 â”‚ \"Street Scene\" â”‚ \"A busy urban street scene captures diverse pedestr...\" â”‚ \"city street, urban, New York City, pedestrians, traffic, cars, taxi, crosswalk, buildings, people, family, baby stroller, daytime, downtown\" â”‚ \"City street\"                â”‚\n",
            "â”‚     1 â”‚ \"Mountain\"     â”‚ \"A breathtaking mountain landscape at sunrise, feat...\" â”‚ \"mountain landscape, sunrise, snow-capped mountains, clouds, golden glow, nature, scenic, dawn\"                                               â”‚ \"outdoor mountain landscape\" â”‚\n",
            "â”‚     2 â”‚ \"Cat\"          â”‚ \"A black and white cat with striking green eyes loo...\" â”‚ \"cat, pet, domestic cat, black and white cat, green eyes, animal, feline, portrait, indoor, bamboo, green wall, cute\"                         â”‚ \"Indoor\"                     â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
          ]
        }
      ],
      "source": [
        "// Sample images to process\n",
        "const sampleImages = [\n",
        "    { url: \"https://storage.googleapis.com/vlm-data-public-prod/hub/examples/image.object-detection/crossroad.jpg\", name: \"Street Scene\" },\n",
        "    { url: \"https://images.unsplash.com/photo-1506905925346-21bda4d32df4?w=400\", name: \"Mountain\" },\n",
        "    { url: \"https://images.unsplash.com/photo-1514888286974-6c03e2ca1dba?w=400\", name: \"Cat\" },\n",
        "];\n",
        "\n",
        "interface BatchCaptionResult {\n",
        "    imageName: string;\n",
        "    caption: string;\n",
        "    tags: string;\n",
        "    sceneType: string;\n",
        "    error?: string;\n",
        "}\n",
        "\n",
        "async function processImagesBatch(images: { url: string; name: string }[]): Promise<BatchCaptionResult[]> {\n",
        "    const results: BatchCaptionResult[] = [];\n",
        "    \n",
        "    for (const img of images) {\n",
        "        try {\n",
        "            console.log(`Processing: ${img.name}...`);\n",
        "            const result = await generateStructuredCaption(img.url);\n",
        "            results.push({\n",
        "                imageName: img.name,\n",
        "                caption: result.caption,\n",
        "                tags: result.tags.join(\", \"),\n",
        "                sceneType: result.scene_type\n",
        "            });\n",
        "        } catch (error) {\n",
        "            console.log(`Error processing ${img.name}: ${error}`);\n",
        "            results.push({\n",
        "                imageName: img.name,\n",
        "                caption: `Error: ${error}`,\n",
        "                tags: \"\",\n",
        "                sceneType: \"\",\n",
        "                error: String(error)\n",
        "            });\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    return results;\n",
        "}\n",
        "\n",
        "// Process all images\n",
        "const batchResults = await processImagesBatch(sampleImages);\n",
        "\n",
        "// Display results\n",
        "console.log(\"\\n=== Batch Processing Results ===\\n\");\n",
        "console.table(batchResults.map(r => ({\n",
        "    Image: r.imageName,\n",
        "    Caption: r.caption.substring(0, 50) + \"...\",\n",
        "    Tags: r.tags,\n",
        "    Scene: r.sceneType\n",
        "})));\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 4: Custom Caption Styles\n",
        "\n",
        "Customize caption output by adjusting the prompt:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "// Different caption styles using the VLM Run SDK\n",
        "const captionStyles: Record<string, string> = {\n",
        "    \"Short & concise\": \"Generate a brief, one-sentence caption for this image.\",\n",
        "    \"Detailed & descriptive\": \"Generate a detailed, descriptive caption for this image with at least 50 words.\",\n",
        "    \"Creative & poetic\": \"Generate a creative and poetic caption for this image.\",\n",
        "    \"SEO-optimized\": \"Generate an SEO-optimized caption for this image that includes relevant keywords.\",\n",
        "    \"Accessibility focused\": \"Generate an accessibility-focused alt text for this image that would help visually impaired users understand the content.\"\n",
        "};\n",
        "\n",
        "console.log(\"Different Caption Styles for the Same Image:\\n\");\n",
        "console.log(\"=\".repeat(80));\n",
        "\n",
        "for (const [styleName, prompt] of Object.entries(captionStyles)) {\n",
        "    const captionResult = await generateCaption(imageUrl, prompt);\n",
        "    console.log(`\\n${styleName.toUpperCase()}:`);\n",
        "    console.log(captionResult);\n",
        "    console.log(\"-\".repeat(80));\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 5: Using VLM Run SDK Image Predictions API\n",
        "\n",
        "The VLM Run SDK also provides a dedicated `image` API for predictions. Let's explore this approach:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ VLM Run main API client initialized!\n",
            "\n",
            "ğŸ“· Using VLM Run Image API for captioning...\n",
            "\n",
            "Image Prediction Response:\n",
            "{\n",
            "  \"usage\": {\n",
            "    \"elements_processed\": 1,\n",
            "    \"element_type\": \"image\",\n",
            "    \"credits_used\": 2,\n",
            "    \"steps\": null,\n",
            "    \"message\": null,\n",
            "    \"duration_seconds\": 0\n",
            "  },\n",
            "  \"id\": \"6a2adca0-1513-4481-9ba4-4db18319b7db\",\n",
            "  \"created_at\": \"2025-12-18T13:48:18.089268\",\n",
            "  \"completed_at\": \"2025-12-18T13:48:26.965723Z\",\n",
            "  \"response\": {\n",
            "    \"caption\": \"A bustling city street scene, likely in New York, captures pedestrians crossing a wide intersection. In the foreground, a family with a child in a stroller walks across a crosswalk, accompanied by other individuals. Yellow taxi cabs and numerous other vehicles are visible in various lanes of traffic, surrounded by towering urban buildings and clear skies in the distance.\",\n",
            "    \"mood\": \"Busy\",\n",
            "    \"primary_objects\": [\n",
            "      \"pedestrians\",\n",
            "      \"yellow taxi cabs\",\n",
            "      \"cars\",\n",
            "      \"stroller\",\n",
            "      \"city buildings\",\n",
            "      \"crosswalk\"\n",
            "    ],\n",
            "    \"scene_type\": \"street\",\n",
            "    \"tags\": [\n",
            "      \"city life\",\n",
            "      \"urban\",\n",
            "      \"New York City\",\n",
            "      \"pedestrians\",\n",
            "      \"traffic\",\n",
            "      \"daytime\",\n",
            "      \"crosswalk\",\n",
            "      \"buildings\",\n",
            "      \"taxi\",\n",
            "      \"people\"\n",
            "    ]\n",
            "  },\n",
            "  \"status\": \"completed\",\n",
            "  \"domain\": \"image.caption\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "// Initialize a separate client for the main API (not agent API)\n",
        "const vlmClient = new VlmRun({\n",
        "    apiKey: VLMRUN_API_KEY,\n",
        "    baseURL: \"https://api.vlm.run/v1\"  \n",
        "});\n",
        "\n",
        "console.log(\"âœ“ VLM Run main API client initialized!\");\n",
        "\n",
        "// Using the image predictions API\n",
        "// Note: This uses the standard prediction API, not the agent API\n",
        "console.log(\"\\nğŸ“· Using VLM Run Image API for captioning...\\n\");\n",
        "\n",
        "try {\n",
        "    // Generate caption using the image.generate method\n",
        "    const imagePrediction = await vlmClient.image.generate({\n",
        "        images: [imageUrl],\n",
        "        model: \"vlm-1\",\n",
        "        domain: \"image.caption\",\n",
        "        config: {\n",
        "            jsonSchema: zodToJsonSchema(ImageCaptionSchema)\n",
        "        }\n",
        "    });\n",
        "    \n",
        "    console.log(\"Image Prediction Response:\");\n",
        "    console.log(JSON.stringify(imagePrediction, null, 2));\n",
        "} catch (error) {\n",
        "    console.log(\"Note: Image predictions API requires specific domain access.\");\n",
        "    console.log(\"For general captioning, use the agent.completions API as shown in previous examples.\");\n",
        "    console.log(\"Error:\", error);\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## VLM Run SDK Features\n",
        "\n",
        "The VLM Run SDK (`vlmrun` npm package) provides several advantages over using the OpenAI client directly:\n",
        "\n",
        "### Key Features\n",
        "\n",
        "| Feature | Description |\n",
        "|---------|-------------|\n",
        "| `agent.completions` | OpenAI-compatible chat completions for agent API |\n",
        "| `image.generate()` | Direct image prediction API access |\n",
        "| `document.generate()` | Document processing capabilities |\n",
        "| `audio.generate()` | Audio transcription and analysis |\n",
        "| `video.generate()` | Video understanding and analysis |\n",
        "| `files.upload()` | File upload for processing |\n",
        "| `hub.list()` | Browse available models and domains |\n",
        "\n",
        "### SDK Initialization Options\n",
        "\n",
        "```typescript\n",
        "const client = new VlmRun({\n",
        "    apiKey: \"your-api-key\",\n",
        "    baseURL: \"https://api.vlm.run/v1\",  // or \"https://agent.vlm.run/v1\"\n",
        "    timeout: 60000,  // Request timeout in ms\n",
        "    maxRetries: 3    // Number of retries for failed requests\n",
        "});\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 6: Exploring Available Models\n",
        "\n",
        "Use the SDK to discover available models and domains:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“‹ Listing available models...\n",
            "\n",
            "Available Models:\n",
            "  - undefined: N/A\n",
            "  - undefined: N/A\n",
            "  - undefined: N/A\n",
            "  - undefined: N/A\n",
            "  - undefined: N/A\n",
            "  - undefined: N/A\n",
            "  - undefined: N/A\n",
            "  - undefined: N/A\n",
            "  - undefined: N/A\n",
            "  - undefined: N/A\n",
            "  - undefined: N/A\n",
            "  - undefined: N/A\n",
            "  - undefined: N/A\n",
            "  - undefined: N/A\n",
            "  - undefined: N/A\n",
            "  - undefined: N/A\n",
            "  - undefined: N/A\n",
            "  - undefined: N/A\n",
            "  - undefined: N/A\n",
            "  - undefined: N/A\n",
            "  - undefined: N/A\n",
            "  - undefined: N/A\n",
            "\n",
            "ğŸ“‹ Listing hub domains for image captioning...\n",
            "\n",
            "Could not list hub domains: TypeError: vlmClient.hub.list is not a function\n",
            "    at <anonymous>:15:40\n",
            "    at Object.runMicrotasks (ext:core/01_core.js:730:26)\n",
            "    at processTicksAndRejections (ext:deno_node/_next_tick.ts:59:10)\n",
            "    at runNextTicks (ext:deno_node/_next_tick.ts:76:3)\n",
            "    at eventLoopTick (ext:core/01_core.js:194:21)\n"
          ]
        }
      ],
      "source": [
        "// List available models using the SDK\n",
        "console.log(\"ğŸ“‹ Listing available models...\\n\");\n",
        "\n",
        "try {\n",
        "    const models = await vlmClient.models.list();\n",
        "    console.log(\"Available Models:\");\n",
        "    models.forEach(model => {\n",
        "        console.log(`  - ${model.id}: ${model.name || 'N/A'}`);\n",
        "    });\n",
        "} catch (error) {\n",
        "    console.log(\"Could not list models:\", error);\n",
        "}\n",
        "\n",
        "// List available hub domains\n",
        "console.log(\"\\nğŸ“‹ Listing hub domains for image captioning...\\n\");\n",
        "\n",
        "try {\n",
        "    const hubItems = await vlmClient.hub.list({ \n",
        "        type: \"image\"  // Filter by image type\n",
        "    });\n",
        "    console.log(\"Available Image Domains:\");\n",
        "    hubItems.slice(0, 10).forEach(item => {\n",
        "        console.log(`  - ${item.domain}: ${item.description || 'N/A'}`);\n",
        "    });\n",
        "    if (hubItems.length > 10) {\n",
        "        console.log(`  ... and ${hubItems.length - 10} more`);\n",
        "    }\n",
        "} catch (error) {\n",
        "    console.log(\"Could not list hub domains:\", error);\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best Practices & Tips\n",
        "\n",
        "### Caption Quality\n",
        "- Be specific in your prompts about the level of detail you need\n",
        "- For accessibility, ask for alt-text specifically\n",
        "- For SEO, ask for keyword-rich descriptions\n",
        "\n",
        "### SDK Usage\n",
        "- Use `agent.completions` for OpenAI-compatible chat interface with image support\n",
        "- Use `image.generate()` for domain-specific image predictions\n",
        "- Set appropriate timeouts for large image processing\n",
        "- Use retry logic for production applications\n",
        "\n",
        "### Performance Tips\n",
        "- Batch similar captioning tasks for efficiency\n",
        "- Consider caching captions to avoid reprocessing\n",
        "- Use appropriate image sizes (doesn't need to be full resolution)\n",
        "\n",
        "### TypeScript Benefits\n",
        "- Use Zod schemas for type-safe structured outputs\n",
        "- Leverage TypeScript's type inference for better IDE support\n",
        "- The VLM Run SDK is fully typed for excellent developer experience\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional Resources\n",
        "\n",
        "- [VLM Run Documentation](https://docs.vlm.run)\n",
        "- [VLM Run Node.js SDK](https://github.com/vlm-run/vlmrun-node-sdk)\n",
        "- [SDK API Reference](https://docs.vlm.run/sdks/node-sdk)\n",
        "- [API Reference](https://docs.vlm.run/agents/capabilities/image/captioning)\n",
        "- [More Examples](https://github.com/vlm-run/vlmrun-cookbook)\n",
        "- [Discord Community](https://discord.gg/AMApC2UzVY)\n",
        "\n",
        "### Installation\n",
        "\n",
        "```bash\n",
        "npm install vlmrun openai zod zod-to-json-schema\n",
        "```\n",
        "\n",
        "### Quick Start\n",
        "\n",
        "```typescript\n",
        "import { VlmRun } from \"vlmrun\";\n",
        "\n",
        "const client = new VlmRun({\n",
        "    apiKey: process.env.VLMRUN_API_KEY,\n",
        "    baseURL: \"https://agent.vlm.run/v1\"\n",
        "});\n",
        "\n",
        "const response = await client.agent.completions.create({\n",
        "    model: \"vlm-agent-1\",\n",
        "    messages: [\n",
        "        {\n",
        "            role: \"user\",\n",
        "            content: [\n",
        "                { type: \"text\", text: \"Describe this image\" },\n",
        "                { type: \"image_url\", image_url: { url: \"https://example.com/image.jpg\" } }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "});\n",
        "\n",
        "console.log(response.choices[0].message.content);\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Deno",
      "language": "typescript",
      "name": "deno"
    },
    "language_info": {
      "codemirror_mode": "typescript",
      "file_extension": ".ts",
      "mimetype": "text/x.typescript",
      "name": "typescript",
      "nbconvert_exporter": "script",
      "pygments_lexer": "typescript",
      "version": "5.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
