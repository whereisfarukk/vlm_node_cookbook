{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align=\"center\">\n",
        "<p align=\"center\" style=\"width: 100%;\">\n",
        "    <img src=\"https://raw.githubusercontent.com/vlm-run/.github/refs/heads/main/profile/assets/vlm-black.svg\" alt=\"VLM Run Logo\" width=\"80\" style=\"margin-bottom: -5px; color: #2e3138; vertical-align: middle; padding-right: 5px;\"><br>\n",
        "</p>\n",
        "<p align=\"center\"><a href=\"https://docs.vlm.run\"><b>Website</b></a> | <a href=\"https://docs.vlm.run/\"><b>API Docs</b></a> | <a href=\"https://docs.vlm.run/blog\"><b>Blog</b></a> | <a href=\"https://discord.gg/AMApC2UzVY\"><b>Discord</b></a>\n",
        "</p>\n",
        "<p align=\"center\">\n",
        "<a href=\"https://discord.gg/AMApC2UzVY\"><img alt=\"Discord\" src=\"https://img.shields.io/badge/discord-chat-purple?color=%235765F2&label=discord&logo=discord\"></a>\n",
        "<a href=\"https://twitter.com/vlmrun\"><img alt=\"Twitter Follow\" src=\"https://img.shields.io/twitter/follow/vlmrun.svg?style=social&logo=twitter\"></a>\n",
        "</p>\n",
        "</div>\n",
        "\n",
        "Welcome to **[VLM Run Cookbooks](https://github.com/vlm-run/vlmrun-cookbook)**, a comprehensive collection of examples and notebooks demonstrating the power of structured visual understanding using the [VLM Run Platform](https://app.vlm.run).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image Captioning & Tagging with VLM Run (Node.js)\n",
        "\n",
        "This notebook demonstrates how to use VLM Run's Agent API to generate detailed captions and tags for images using **Node.js/TypeScript**. Image captioning is perfect for:\n",
        "- **Accessibility**: Creating alt-text descriptions for images\n",
        "- **Content Management**: Automatically organizing and cataloging image libraries\n",
        "- **SEO**: Generating image descriptions for better search engine optimization\n",
        "- **Automated Analysis**: Building workflows that understand visual content\n",
        "\n",
        "We'll use VLM Run's vision-language models to generate comprehensive, contextual captions and extract relevant tags from various images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Environment Setup\n",
        "\n",
        "To get started, install the required packages and sign up for an API key on the [VLM Run App](https://app.vlm.run).\n",
        "- Store the VLM Run API key under the `VLMRUN_API_KEY` environment variable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "\n",
        "* Node.js 18+\n",
        "* VLM Run API key (get one at [app.vlm.run](https://app.vlm.run))\n",
        "* Deno or tslab kernel for running TypeScript in Jupyter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "First, let's install the required packages:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "// If using Deno kernel, install dependencies via npm specifiers\n",
        "// For tslab, run: npm install openai zod zod-to-json-schema in your project directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import OpenAI from \"openai\";\n",
        "import { z } from \"zod\";\n",
        "import { zodToJsonSchema } from \"npm:zod-to-json-schema\";\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ API Key loaded successfully\n"
          ]
        }
      ],
      "source": [
        "// Get API key from environment variable\n",
        "const VLMRUN_API_KEY = Deno.env.get(\"VLMRUN_API_KEY\");\n",
        "\n",
        "if (!VLMRUN_API_KEY) {\n",
        "    throw new Error(\"Please set the VLMRUN_API_KEY environment variable\");\n",
        "}\n",
        "\n",
        "console.log(\"âœ“ API Key loaded successfully\");\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's initialize the OpenAI client with VLM Run's Agent API endpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ OpenAI client initialized with VLM Run Agent API\n"
          ]
        }
      ],
      "source": [
        "// Initialize the OpenAI client with VLM Run's Agent API\n",
        "const client = new OpenAI({\n",
        "    baseURL: \"https://agent.vlm.run/v1/openai\",\n",
        "    apiKey: VLMRUN_API_KEY\n",
        "});\n",
        "\n",
        "console.log(\"âœ“ OpenAI client initialized with VLM Run Agent API\");\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 1: Simple Image Captioning\n",
        "\n",
        "Let's start with a simple example - generating a caption for a single image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image URL: https://storage.googleapis.com/vlm-data-public-prod/hub/examples/image.object-detection/crossroad.jpg\n",
            "\n",
            "ğŸ“· View the image: https://storage.googleapis.com/vlm-data-public-prod/hub/examples/image.object-detection/crossroad.jpg\n"
          ]
        }
      ],
      "source": [
        "// Example image URL\n",
        "const imageUrl = \"https://storage.googleapis.com/vlm-data-public-prod/hub/examples/image.object-detection/crossroad.jpg\";\n",
        "\n",
        "// Display the image URL (in Jupyter, you can use display functions)\n",
        "console.log(\"Image URL:\", imageUrl);\n",
        "console.log(\"\\nğŸ“· View the image:\", imageUrl);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's generate a caption for this image:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Caption: This eye-level shot captures a bustling city street scene, likely in New York City, with towering commercial buildings lining both sides. A diverse group of pedestrians crosses a marked crosswalk, including an adult man with a beard and light blue shirt leading a woman, a small child, and another child in a stroller. Another man with a backpack walks past a bright yellow taxi cab in the mid-ground. The street is filled with various vehicles, including multiple yellow taxis and other cars, reflecting the dynamic urban environment. Storefronts and street signs add to the lively city atmosphere.\n"
          ]
        }
      ],
      "source": [
        "// Define a helper function to generate captions\n",
        "async function generateCaption(\n",
        "    imageUrl: string, \n",
        "    prompt: string = \"Generate a detailed caption for this image\"\n",
        "): Promise<string> {\n",
        "    /**\n",
        "     * Generate a caption for an image using VLM Run's Agent API.\n",
        "     */\n",
        "    const response = await client.chat.completions.create({\n",
        "        model: \"vlm-agent-1\",\n",
        "        messages: [\n",
        "            {\n",
        "                role: \"user\",\n",
        "                content: [\n",
        "                    { type: \"text\", text: prompt },\n",
        "                    { type: \"image_url\", image_url: { url: imageUrl } }\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    });\n",
        "    \n",
        "    return response.choices[0].message.content || \"\";\n",
        "}\n",
        "\n",
        "// Generate caption for the image\n",
        "const caption = await generateCaption(imageUrl);\n",
        "console.log(`Caption: ${caption}`);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 2: Structured Output with Zod Schema\n",
        "\n",
        "For production applications, you might want structured JSON output. Let's use Zod schemas (Node.js equivalent of Python's Pydantic) with OpenAI's structured outputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JSON Schema: {\n",
            "  \"$ref\": \"#/definitions/ImageCaption\",\n",
            "  \"definitions\": {\n",
            "    \"ImageCaption\": {\n",
            "      \"type\": \"object\",\n",
            "      \"properties\": {\n",
            "        \"caption\": {\n",
            "          \"type\": \"string\",\n",
            "          \"description\": \"Detailed caption of the scene\"\n",
            "        },\n",
            "        \"tags\": {\n",
            "          \"type\": \"array\",\n",
            "          \"items\": {\n",
            "            \"type\": \"string\"\n",
            "          },\n",
            "          \"description\": \"Tags that describe the image\"\n",
            "        },\n",
            "        \"primary_objects\": {\n",
            "          \"type\": \"array\",\n",
            "          \"items\": {\n",
            "            \"type\": \"string\"\n",
            "          },\n",
            "          \"description\": \"Main objects visible in the image\"\n",
            "        },\n",
            "        \"scene_type\": {\n",
            "          \"type\": \"string\",\n",
            "          \"description\": \"Type of scene (e.g., indoor, outdoor, street, nature)\"\n",
            "        }\n",
            "      },\n",
            "      \"required\": [\n",
            "        \"caption\",\n",
            "        \"tags\",\n",
            "        \"primary_objects\",\n",
            "        \"scene_type\"\n",
            "      ],\n",
            "      \"additionalProperties\": false\n",
            "    }\n",
            "  },\n",
            "  \"$schema\": \"http://json-schema.org/draft-07/schema#\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "// Define the schema using Zod\n",
        "const ImageCaptionSchema = z.object({\n",
        "    caption: z.string().describe(\"Detailed caption of the scene\"),\n",
        "    tags: z.array(z.string()).describe(\"Tags that describe the image\"),\n",
        "    primary_objects: z.array(z.string()).describe(\"Main objects visible in the image\"),\n",
        "    scene_type: z.string().describe(\"Type of scene (e.g., indoor, outdoor, street, nature)\")\n",
        "});\n",
        "\n",
        "// Type inference from schema\n",
        "type ImageCaption = z.infer<typeof ImageCaptionSchema>;\n",
        "\n",
        "// Convert Zod schema to JSON Schema for API\n",
        "const jsonSchema = zodToJsonSchema(ImageCaptionSchema, \"ImageCaption\");\n",
        "console.log(\"JSON Schema:\", JSON.stringify(jsonSchema, null, 2));\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw JSON Response:\n",
            "{\"caption\":\"The image captures a bustling urban street scene during the daytime, likely in a major city such as New York, indicated by the yellow taxi cab. In the foreground and midground, several pedestrians are actively crossing a wide street at a crosswalk. On the right, a man with a beard, wearing a light blue shirt and khaki pants, walks briskly, holding a phone and wearing earbuds. Beside him, a woman pushes a stroller containing a small child, while another young child walks alongside the stroller. On the left side of the crosswalk, a man with a backpack, dressed in a dark jacket and jeans, stands near a yellow Toyota RAV4 taxi. The street is filled with various vehicles, including parked cars, SUVs, and a white commercial van, and more traffic is visible further down the street. The background is dominated by tall, densely packed commercial and residential buildings lining both sides of the street, some featuring prominent signs like 'Office' and large billboards, characteristic of a metropolitan area. The sky, visible between the distant buildings, appears clear. The overall atmosphere is one of dynamic urban activity, portraying a typical busy day in a vibrant city environment.\",\"primary_objects\":[\"Pedestrians\",\"Yellow taxi cab\",\"Stroller\",\"Vehicles\",\"Tall buildings\",\"Billboards\",\"Signs\"],\"scene_type\":\"Urban street scene\",\"tags\":[\"City\",\"Street\",\"Daytime\",\"Busy\",\"Crosswalk\",\"Traffic\",\"Buildings\",\"Taxis\",\"People\",\"New York\",\"Urban\",\"Metropolis\",\"Pedestrian\",\"Vehicles\",\"Office buildings\",\"Billboards\"]}\n",
            "\n",
            "Validated Object:\n",
            "{\n",
            "  caption: \"The image captures a bustling urban street scene during the daytime, likely in a major city such as New York, indicated by the yellow taxi cab. In the foreground and midground, several pedestrians are actively crossing a wide street at a crosswalk. On the right, a man with a beard, wearing a light blue shirt and khaki pants, walks briskly, holding a phone and wearing earbuds. Beside him, a woman pushes a stroller containing a small child, while another young child walks alongside the stroller. On the left side of the crosswalk, a man with a backpack, dressed in a dark jacket and jeans, stands near a yellow Toyota RAV4 taxi. The street is filled with various vehicles, including parked cars, SUVs, and a white commercial van, and more traffic is visible further down the street. The background is dominated by tall, densely packed commercial and residential buildings lining both sides of the street, some featuring prominent signs like 'Office' and large billboards, characteristic of a metropolitan area. The sky, visible between the distant buildings, appears clear. The overall atmosphere is one of dynamic urban activity, portraying a typical busy day in a vibrant city environment.\",\n",
            "  tags: [\n",
            "    \"City\",             \"Street\",\n",
            "    \"Daytime\",          \"Busy\",\n",
            "    \"Crosswalk\",        \"Traffic\",\n",
            "    \"Buildings\",        \"Taxis\",\n",
            "    \"People\",           \"New York\",\n",
            "    \"Urban\",            \"Metropolis\",\n",
            "    \"Pedestrian\",       \"Vehicles\",\n",
            "    \"Office buildings\", \"Billboards\"\n",
            "  ],\n",
            "  primary_objects: [\n",
            "    \"Pedestrians\",\n",
            "    \"Yellow taxi cab\",\n",
            "    \"Stroller\",\n",
            "    \"Vehicles\",\n",
            "    \"Tall buildings\",\n",
            "    \"Billboards\",\n",
            "    \"Signs\"\n",
            "  ],\n",
            "  scene_type: \"Urban street scene\"\n",
            "}\n",
            "\n",
            "Formatted Output:\n",
            "Caption: The image captures a bustling urban street scene during the daytime, likely in a major city such as New York, indicated by the yellow taxi cab. In the foreground and midground, several pedestrians are actively crossing a wide street at a crosswalk. On the right, a man with a beard, wearing a light blue shirt and khaki pants, walks briskly, holding a phone and wearing earbuds. Beside him, a woman pushes a stroller containing a small child, while another young child walks alongside the stroller. On the left side of the crosswalk, a man with a backpack, dressed in a dark jacket and jeans, stands near a yellow Toyota RAV4 taxi. The street is filled with various vehicles, including parked cars, SUVs, and a white commercial van, and more traffic is visible further down the street. The background is dominated by tall, densely packed commercial and residential buildings lining both sides of the street, some featuring prominent signs like 'Office' and large billboards, characteristic of a metropolitan area. The sky, visible between the distant buildings, appears clear. The overall atmosphere is one of dynamic urban activity, portraying a typical busy day in a vibrant city environment.\n",
            "Tags: City, Street, Daytime, Busy, Crosswalk, Traffic, Buildings, Taxis, People, New York, Urban, Metropolis, Pedestrian, Vehicles, Office buildings, Billboards\n",
            "Primary Objects: Pedestrians, Yellow taxi cab, Stroller, Vehicles, Tall buildings, Billboards, Signs\n",
            "Scene Type: Urban street scene\n"
          ]
        }
      ],
      "source": [
        "async function generateStructuredCaption(imageUrl: string): Promise<ImageCaption> {\n",
        "    /**\n",
        "     * Generate a structured caption using Zod schemas and JSON Schema.\n",
        "     */\n",
        "    const response = await client.chat.completions.create({\n",
        "        model: \"vlm-agent-1\",\n",
        "        messages: [\n",
        "            {\n",
        "                role: \"user\",\n",
        "                content: [\n",
        "                    { \n",
        "                        type: \"text\", \n",
        "                        text: \"Analyze this image and provide a detailed caption, relevant tags, primary objects, and scene type.\" \n",
        "                    },\n",
        "                    { \n",
        "                        type: \"image_url\", \n",
        "                        image_url: { url: imageUrl, detail: \"auto\" } \n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        // Use VLM Run's format - schema at top level, not nested under json_schema\n",
        "        response_format: { \n",
        "            type: \"json_schema\", \n",
        "            schema: zodToJsonSchema(ImageCaptionSchema)\n",
        "        } as any  // Type assertion needed since this differs from OpenAI's type\n",
        "    });\n",
        "    \n",
        "    // Print the raw JSON response\n",
        "    const rawContent = response.choices[0].message.content || \"{}\";\n",
        "    console.log(\"Raw JSON Response:\");\n",
        "    console.log(rawContent);\n",
        "    console.log();\n",
        "    \n",
        "    // Parse and validate the response\n",
        "    const parsed = JSON.parse(rawContent);\n",
        "    return ImageCaptionSchema.parse(parsed);\n",
        "}\n",
        "\n",
        "// Generate structured caption\n",
        "const structuredResult = await generateStructuredCaption(imageUrl);\n",
        "\n",
        "console.log(\"Validated Object:\");\n",
        "console.log(structuredResult);\n",
        "console.log();\n",
        "console.log(\"Formatted Output:\");\n",
        "console.log(`Caption: ${structuredResult.caption}`);\n",
        "console.log(`Tags: ${structuredResult.tags.join(\", \")}`);\n",
        "console.log(`Primary Objects: ${structuredResult.primary_objects.join(\", \")}`);\n",
        "console.log(`Scene Type: ${structuredResult.scene_type}`);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 3: Batch Processing Multiple Images\n",
        "\n",
        "Let's process multiple images and display the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing: https://storage.googleapis.com/vlm-data-public-prod/hub/examples/image.caption/car.jpg\n",
            "Raw JSON Response:\n",
            "{\"caption\":\"The image features a light blue or teal vintage Volkswagen Beetle, prominently parked on a cobblestone or paved street. The car is well-maintained, showcasing chrome bumpers and hubcaps. In the background, there is a building with a light yellow or ochre-colored stucco wall. This wall contains two distinct wooden entrances: one is a double door with an arched top, and the other is a single rectangular door framed in white. The scene is brightly lit, suggesting a sunny day, and the overall atmosphere is calm and nostalgic, reminiscent of a charming, older urban setting.\",\"primary_objects\":[\"light blue classic car (a Volkswagen Beetle)\",\"building facade with a light yellow wall\",\"wooden door\",\"wooden window\"],\"scene_type\":\"Street\",\"tags\":[\"car\",\"Volkswagen Beetle\",\"classic car\",\"vintage car\",\"automobile\",\"vehicle\",\"turquoise car\",\"mint green car\",\"light blue car\",\"street\",\"building\",\"old building\",\"wooden door\",\"urban\",\"retro\",\"architecture\",\"pavement\",\"outdoors\",\"daytime\",\"side view\",\"parked car\",\"vintage Volkswagen\",\"VW Beetle\"]}\n",
            "\n",
            "Processing: https://images.unsplash.com/photo-1506905925346-21bda4d32df4?w=400\n",
            "Raw JSON Response:\n",
            "{\"caption\":\"A breathtaking high-angle view captures a majestic mountain range at either sunrise or sunset, with a prominent snow-capped peak standing tall amidst other rugged, snow-dusted mountains. A thick, ethereal 'sea of clouds' fills the valley below, extending across the midground. The sky above is painted with soft hues of pink and orange near the horizon, gradually blending into cooler blues overhead, while the peaks catch the warm, golden light of the low sun. Dark, rocky, and possibly frosted terrain occupies the immediate foreground, providing a stark contrast to the distant, illuminated peaks and cloud-filled expanse.\",\"primary_objects\":[\"mountains\",\"clouds/fog\",\"sky\"],\"scene_type\":\"mountain landscape with a cloud inversion at either sunrise or sunset\",\"tags\":[\"mountains\",\"landscape\",\"sunset\",\"sunrise\",\"clouds\",\"sea of clouds\",\"snow\",\"peaks\",\"nature\",\"alpine\",\"valley\",\"outdoor\"]}\n",
            "\n",
            "Processing: https://images.unsplash.com/photo-1514888286974-6c03e2ca1dba?w=400\n",
            "Raw JSON Response:\n",
            "{\"caption\":\"A black and white tuxedo cat with bright green eyes looks directly at the camera, with its front paws resting on a light brown, bamboo-like structure. The background is a solid, light green wall.\",\"primary_objects\":[\"black and white cat\",\"light brown bamboo-like surface\",\"green background\"],\"scene_type\":\"Portrait\",\"tags\":[\"cat\",\"black and white cat\",\"tuxedo cat\",\"green eyes\",\"pet\",\"animal\",\"feline\",\"domestic animal\",\"green background\",\"bamboo\",\"portrait\"]}\n",
            "\n",
            "Processing: https://images.unsplash.com/photo-1449034446853-66c86144b0ad?w=400\n",
            "Raw JSON Response:\n",
            "{\"caption\":\"An iconic view of the Golden Gate Bridge stretching across the water during either sunrise or sunset, bathed in a warm, golden light that contrasts with the teal and blue hues of the sky. The bridge, with its classic orange-red color, carries traffic, while hills covered in vegetation are visible in the foreground. Distant land or a city skyline can be seen on the far side, and a boat navigates the water beneath the bridge, all under a dynamic sky with scattered clouds.\",\"primary_objects\":[\"bridge\",\"water\",\"land\",\"sky\"],\"scene_type\":\"Landscape\",\"tags\":[\"Golden Gate Bridge\",\"San Francisco\",\"bridge\",\"landmark\",\"sunset\",\"architecture\",\"travel\",\"cityscape\",\"bay\",\"water\",\"sky\",\"California\",\"USA\"]}\n",
            "\n",
            "\n",
            "=== Batch Processing Results ===\n",
            "â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "â”‚ (idx) â”‚ url                                                     â”‚ caption                                                           â”‚ tags                                                                                                                                                                                                                                                                               â”‚ sceneType                                                               â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚     0 â”‚ \"https://storage.googleapis.com/vlm-data-public-pro...\" â”‚ \"The image features a light blue or teal vintage Volkswagen B...\" â”‚ \"car, Volkswagen Beetle, classic car, vintage car, automobile, vehicle, turquoise car, mint green car, light blue car, street, building, old building, wooden door, urban, retro, architecture, pavement, outdoors, daytime, side view, parked car, vintage Volkswagen, VW Beetle\" â”‚ \"Street\"                                                                â”‚\n",
            "â”‚     1 â”‚ \"https://images.unsplash.com/photo-1506905925346-21...\" â”‚ \"A breathtaking high-angle view captures a majestic mountain ...\" â”‚ \"mountains, landscape, sunset, sunrise, clouds, sea of clouds, snow, peaks, nature, alpine, valley, outdoor\"                                                                                                                                                                       â”‚ \"mountain landscape with a cloud inversion at either sunrise or sunset\" â”‚\n",
            "â”‚     2 â”‚ \"https://images.unsplash.com/photo-1514888286974-6c...\" â”‚ \"A black and white tuxedo cat with bright green eyes looks di...\" â”‚ \"cat, black and white cat, tuxedo cat, green eyes, pet, animal, feline, domestic animal, green background, bamboo, portrait\"                                                                                                                                                       â”‚ \"Portrait\"                                                              â”‚\n",
            "â”‚     3 â”‚ \"https://images.unsplash.com/photo-1449034446853-66...\" â”‚ \"An iconic view of the Golden Gate Bridge stretching across t...\" â”‚ \"Golden Gate Bridge, San Francisco, bridge, landmark, sunset, architecture, travel, cityscape, bay, water, sky, California, USA\"                                                                                                                                                   â”‚ \"Landscape\"                                                             â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
          ]
        }
      ],
      "source": [
        "// Sample images to process\n",
        "const sampleImages = [\n",
        "    \"https://storage.googleapis.com/vlm-data-public-prod/hub/examples/image.caption/car.jpg\",\n",
        "    \"https://images.unsplash.com/photo-1506905925346-21bda4d32df4?w=400\",  // Mountain landscape\n",
        "    \"https://images.unsplash.com/photo-1514888286974-6c03e2ca1dba?w=400\",  // Cat\n",
        "    \"https://images.unsplash.com/photo-1449034446853-66c86144b0ad?w=400\",  // City buildings\n",
        "];\n",
        "\n",
        "interface BatchResult {\n",
        "    imageUrl: string;\n",
        "    caption: string;\n",
        "    tags: string;\n",
        "    primaryObjects: string;\n",
        "    sceneType: string;\n",
        "    error?: string;\n",
        "}\n",
        "\n",
        "async function processImagesBatch(imageUrls: string[]): Promise<BatchResult[]> {\n",
        "    /**\n",
        "     * Process multiple images and return structured results.\n",
        "     */\n",
        "    const results: BatchResult[] = [];\n",
        "    \n",
        "    for (const url of imageUrls) {\n",
        "        try {\n",
        "            console.log(`Processing: ${url}`);\n",
        "            const result = await generateStructuredCaption(url);\n",
        "            results.push({\n",
        "                imageUrl: url,\n",
        "                caption: result.caption,\n",
        "                tags: result.tags.join(\", \"),\n",
        "                primaryObjects: result.primary_objects.join(\", \"),\n",
        "                sceneType: result.scene_type\n",
        "            });\n",
        "        } catch (error) {\n",
        "            console.log(`Error processing ${url}: ${error}`);\n",
        "            results.push({\n",
        "                imageUrl: url,\n",
        "                caption: `Error: ${error}`,\n",
        "                tags: \"\",\n",
        "                primaryObjects: \"\",\n",
        "                sceneType: \"\",\n",
        "                error: String(error)\n",
        "            });\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    return results;\n",
        "}\n",
        "\n",
        "// Process images\n",
        "const batchResults = await processImagesBatch(sampleImages);\n",
        "\n",
        "// Display results as a table\n",
        "console.log(\"\\n=== Batch Processing Results ===\");\n",
        "console.table(batchResults.map(r => ({\n",
        "    url: r.imageUrl.substring(0, 50) + \"...\",\n",
        "    caption: r.caption.substring(0, 60) + \"...\",\n",
        "    tags: r.tags,\n",
        "    sceneType: r.sceneType\n",
        "})));\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 4: Custom Caption Styles\n",
        "\n",
        "You can customize the caption style by adjusting the prompt. Let's try different captioning approaches.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Different Caption Styles for the Same Image:\n",
            "\n",
            "================================================================================\n",
            "\n",
            "SHORT & CONCISE:\n",
            "A family with a stroller crosses a busy New York City street, filled with yellow taxis and towering buildings.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "DETAILED & DESCRIPTIVE:\n",
            "A bustling urban street scene unfolds, likely in New York City, depicting a moment of pedestrian activity and vehicular traffic. In the foreground, several individuals are crossing a wide street at a marked crosswalk. Prominently featured is a family unit, with two adults and a small child being pushed in a blue stroller, moving from right to left. A man with a backpack walks on the left, positioned near a bright yellow taxi cab. The street is lined with numerous tall buildings, characteristic of a metropolitan area, some displaying advertisements and signs like 'Office'. Various cars and vans are visible on the road, both parked and in motion, adding to the dynamic cityscape under what appears to be a clear sky.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "CREATIVE & POETIC:\n",
            "In the city's pulse, a symphony of feet,\n",
            "Where concrete canyons rise and dreams alight.\n",
            "Yellow cabs like fireflies dance down the street,\n",
            "And stories cross the canvas, day and night.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "SEO-OPTIMIZED:\n",
            "\"New York City's vibrant pulse captured: A family, with children in a stroller, navigates a busy crosswalk amidst iconic yellow taxis and towering urban architecture. Experience the dynamic energy of city life and bustling urban traffic.\"\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "ACCESSIBILITY FOCUSED:\n",
            "A busy street scene in a city, likely New York, with tall buildings, yellow taxis, and a diverse group of pedestrians including a family with a stroller, crossing at a crosswalk.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "// Different caption styles\n",
        "const captionStyles: Record<string, string> = {\n",
        "    \"Short & concise\": \"Generate a brief, one-sentence caption for this image.\",\n",
        "    \"Detailed & descriptive\": \"Generate a detailed, descriptive caption for this image with at least 50 words.\",\n",
        "    \"Creative & poetic\": \"Generate a creative and poetic caption for this image.\",\n",
        "    \"SEO-optimized\": \"Generate an SEO-optimized caption for this image that includes relevant keywords.\",\n",
        "    \"Accessibility focused\": \"Generate an accessibility-focused alt text for this image that would help visually impaired users understand the content.\"\n",
        "};\n",
        "\n",
        "console.log(\"Different Caption Styles for the Same Image:\\n\");\n",
        "console.log(\"=\".repeat(80));\n",
        "\n",
        "for (const [styleName, prompt] of Object.entries(captionStyles)) {\n",
        "    const captionResult = await generateCaption(imageUrl, prompt);\n",
        "    console.log(`\\n${styleName.toUpperCase()}:`);\n",
        "    console.log(captionResult);\n",
        "    console.log(\"-\".repeat(80));\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 5: Using the VLM Run Node.js SDK\n",
        "\n",
        "You can also use the official VLM Run Node.js SDK which provides a convenient wrapper around the OpenAI client.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ’¡ The VLM Run SDK provides a convenient wrapper around the OpenAI client.\n",
            "   Install it with: npm install vlmrun\n"
          ]
        }
      ],
      "source": [
        "// Alternative: Using VLM Run SDK directly\n",
        "// import { VlmRun } from \"vlmrun\";\n",
        "// \n",
        "// const vlmClient = new VlmRun({\n",
        "//     apiKey: VLMRUN_API_KEY,\n",
        "//     baseURL: \"https://agent.vlm.run/v1\"\n",
        "// });\n",
        "// \n",
        "// // Use the agent completions interface\n",
        "// const response = await vlmClient.agent.completions.create({\n",
        "//     model: \"vlm-agent-1\",\n",
        "//     messages: [\n",
        "//         {\n",
        "//             role: \"user\",\n",
        "//             content: [\n",
        "//                 { type: \"text\", text: \"Describe this image\" },\n",
        "//                 { type: \"image_url\", image_url: { url: imageUrl } }\n",
        "//             ]\n",
        "//         }\n",
        "//     ]\n",
        "// });\n",
        "// \n",
        "// console.log(response.choices[0].message.content);\n",
        "\n",
        "console.log(\"ğŸ’¡ The VLM Run SDK provides a convenient wrapper around the OpenAI client.\");\n",
        "console.log(\"   Install it with: npm install vlmrun\");\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best Practices & Tips\n",
        "\n",
        "### Caption Quality\n",
        "- Be specific in your prompts about the level of detail you need\n",
        "- For accessibility, ask for alt-text specifically\n",
        "- For SEO, ask for keyword-rich descriptions\n",
        "\n",
        "### Performance\n",
        "- Use batch processing for multiple images\n",
        "- Consider caching captions to avoid reprocessing\n",
        "- Use appropriate image sizes (doesn't need to be full resolution)\n",
        "\n",
        "### TypeScript Benefits\n",
        "- Use Zod schemas for type-safe structured outputs\n",
        "- Leverage TypeScript's type inference for better IDE support\n",
        "- Use async/await for cleaner asynchronous code\n",
        "\n",
        "### Tag Categories\n",
        "VLM Run supports various tag types:\n",
        "- **Objects**: person, car, truck, bus, bicycle, motorcycle\n",
        "- **Scenes**: street, building, park, forest, beach\n",
        "- **Time**: morning, afternoon, evening, night\n",
        "- **Weather**: sunny, cloudy, rainy, snowing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional Resources\n",
        "\n",
        "- [VLM Run Documentation](https://docs.vlm.run)\n",
        "- [API Reference](https://docs.vlm.run/agents/capabilities/image/captioning)\n",
        "- [VLM Run Node.js SDK](https://github.com/vlm-run/vlmrun-node-sdk)\n",
        "- [More Examples](https://github.com/vlm-run/vlmrun-cookbook)\n",
        "- [Discord Community](https://discord.gg/AMApC2UzVY)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Deno",
      "language": "typescript",
      "name": "deno"
    },
    "language_info": {
      "codemirror_mode": "typescript",
      "file_extension": ".ts",
      "mimetype": "text/x.typescript",
      "name": "typescript",
      "nbconvert_exporter": "script",
      "pygments_lexer": "typescript",
      "version": "5.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
